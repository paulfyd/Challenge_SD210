{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDTSIA210 Data Challenge - Marine Mercier & Paul Fayard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from time import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier,StackingClassifier\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "import scipy.stats as st\n",
    "\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge : Fusion of algorithms for face recognition\n",
    "\n",
    "In this challenge, the goal is to build a fusion of algorithms in order to construct the best suited solution for comparison of a pair of images.\n",
    "\n",
    "Comparing of two images is done in two steps. 1st, a vector of features is computed for each image. 2nd, a simple function produces a vector of scores for a pair of images. The goal is to create a function that will compare a pair of images based on the information mentioned above, and decide whether two images belong to the same person.\n",
    "\n",
    "Note on our work: \n",
    "\n",
    "We both worked locally on our devices. \n",
    "As it was difficult to work on a single notebook, we decided to share the work. Everyone worked on different methods, and we regularly shared our observations and results in order to move in the same direction. \n",
    "At the end, we merged the two notebooks and obtained this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('xtrain_challenge.csv', delimiter=',', skiprows = 1)\n",
    "Y = np.loadtxt('ytrain_challenge.csv', delimiter=',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data that we are going to predict at the end\n",
    "X_exam = np.loadtxt('xtest_challenge.csv', delimiter=',', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"X_exam.npy\",X_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the data to make sure that our training/test sets are representative of the overall distribution of the data, and therefore, to make sure that we are not going to overfit on a small proportion of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=X.shape[0]\n",
    "ordre=np.arange(0,N)\n",
    "np.random.shuffle(ordre)\n",
    "\n",
    "# Use as new variables\n",
    "X=X[ordre[:]]\n",
    "Y=Y[ordre[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our work was to try to understand the dataset we had to work on. \n",
    "We had a total of 1,068,504 training observations from which we had to train a model to predict 3,318,296 test observations. \n",
    "Each of the training observations, corresponding to two images, has 37 features and one label: 0 or 1. The label is 1 if the two images correspond to the same person, 0 otherwise. We are thus in the case of supervised learning and more precisely of binary classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the labels is  (1068504,) .\n",
      "The training set consists of labels:  [0. 1.]\n",
      "The shape of the observations is  (1068504, 37) .\n",
      "We work with  1068504  data and each one has  37  features.\n",
      "We are going to predict  3318296  new observations.\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the labels is \",Y.shape,\".\")\n",
    "print(\"The training set consists of labels: \",np.unique(Y))\n",
    "print(\"The shape of the observations is \",X.shape,\".\")\n",
    "print(\"We work with \",X.shape[0],\" data and each one has \",X.shape[1],\" features.\")\n",
    "print(\"We are going to predict \",X_exam.shape[0],\" new observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7054610932668477 % of the observations have the label 1.\n",
      "96.29453890673315 % of the observations have the label 0.\n"
     ]
    }
   ],
   "source": [
    "print(str(Y.mean()*100),\"% of the observations have the label 1.\")\n",
    "print(str((1-Y.mean())*100),\"% of the observations have the label 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We soon noticed that the classes were very unbalanced. \n",
    "Indeed, among the training observations, more than 96% of the data had the label 0.\n",
    "We thought that we would have to adapt our algorithms to this imbalance because, it could be that our classifier only learns the majority class, and returns the label 0 for each data.\n",
    "\n",
    "First of all, we thought we would do ***data augmentation***, i.e. create new training observations from our training observations with label 0. You'll see that Marine has worked on it in her notebook. \n",
    "\n",
    "On the other hand, we saw that most classifiers had a ***\"class_weight\" argument*** which allowed us to give more or less importance to the different classes in the loss function. Thus, we played with this parameter, penalizing more an error on a label 1 training observation than an error on a label 0 training observation. \n",
    "All we wanted to ***avoid was that our model doesn't systematically return 0***, and most classifiers didn't need this to learn something from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best accuracy for our predictions, we have to work with good data. \n",
    "Our first reflex was to use a linear transformation to standardize our data (mean=0 and std=1). We applied this to the training and the test set. This avoids that some features are more important than others for no reason. We will see that it has been useful for some of our models, such as SVM or MLPClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Scale data (each feature will have average equal to 0 and unit variance)\\n\\nscaler = StandardScaler()\\nscaler.fit(X)\\nX_scale=scaler.transform(X)\\nX_exam_scale=scaler.transform(X_exam)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Scale data (each feature will have average equal to 0 and unit variance)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scale=scaler.transform(X)\n",
    "X_exam_scale=scaler.transform(X_exam)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Division of the data in training set / test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we had our standardized data, the big question was: how are we going to divide our data?\n",
    "Because we have over 1 million observations we knew that if we worked with all of them, the model training would be very long (espacially the choice of the hyper-parameters). \n",
    "\n",
    "So we made the choice to shuffle our data and to work with 1/8 of the data at the beginning, at the risk of losing a little bit of accuracy. Once the model has been chosen, we will work with all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(X)\n",
    "\n",
    "X_small=X[:N//8]\n",
    "Y_small=Y[:N//8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : In this notebook, we work with an eighth of the data. \n",
    "\n",
    "In other notebooks, we tested the different classifiers with all the data. For some models this was very time consuming, so we can't start all over again in this notebook. That's why here we work with one out of eight data, which was not the case at the time of submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then divided our data into two sets, the training set, and the test set which will allow us to test our models, and above all to check that we haven't overfitted them. The latter is made up of 33% of the data retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To work with all the data.\n"
     ]
    }
   ],
   "source": [
    "if small==1:\n",
    "    \n",
    "    print(\"To work with 1/8 of the data (to make faster training/tests).\")\n",
    "    X_train, X_test ,y_train, y_test = train_test_split(X_small,Y_small, test_size=0.20, random_state=42)\n",
    "else:\n",
    "    print(\"To work with all the data.\") \n",
    "    X_train, X_test ,y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, our approach was to test different models as we went along.\n",
    "We used simple model at the beginning, but we quickly realized that, due to the number of data and the size of the features, we needed a very complex model to learn such important data.\n",
    "\n",
    "We then compared the scores of our different classifiers, scores on the test set, to finally retain the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print the confusion matrix\n",
    "\n",
    "# Code from scikit-learn\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "classes_name=[\"label 0\",\"label 1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(cv_results, grid_param_1, grid_param_2, name_param_1, name_param_2):\n",
    "    # Get Test Scores Mean and std for each grid search\n",
    "    scores_mean = cv_results['mean_test_score']\n",
    "    scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
    "\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots(1,1,figsize=(20,15))\n",
    "\n",
    "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
    "    for idx, val in enumerate(grid_param_2):\n",
    "        ax.plot(grid_param_1, scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
    "\n",
    "    ax.set_title(\"Grid Search Scores, random_state\", fontsize=20, fontweight='bold')\n",
    "    ax.set_xlabel(name_param_1, fontsize=16)\n",
    "    ax.set_ylabel('CV Average Score', fontsize=16)\n",
    "    ax.legend(loc=\"best\", fontsize=15)\n",
    "    ax.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(y_exam=None,model=None,X_exam=None):\n",
    "    #save our results in a csv file\n",
    "    if model !=None:\n",
    "        y_exam=model.predict(X_exam)\n",
    "    np.savetxt('ytest_challenge_student.csv', y_exam, fmt = '%1.0d', delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- First try with KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Knn is a very ***simple*** model. We use it to make a first test and see if we can draw some conclusions.\n",
    "\n",
    "We work will 1/8 of the data because the ***prediction step is very long*** with this method, as we must evaluate such a great number of distances.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We use the default parameters : n_neighbors=5\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9979316799251287"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=KNN.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.72298131995657 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99494891e-01 5.05109376e-04]\n",
      " [6.25000000e-02 9.37500000e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=KNN.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.title(\"Confusion matrix : KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilan : \n",
    "\n",
    "Dataset| Scores \n",
    "- |-: \n",
    "training set  | 99,79%\n",
    "test set | 99,72% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "We see that even we a very simple model, we reach excellent scores. It predicts perfectly the class 0. There are a ***few mistakes over the label 1***, that is the minority class.\n",
    "\n",
    "Without looking as the best parameter for n_neihbors, we are going to test directly a more complex classifier.\n",
    "In fact, the KNN method is not often used because of its ***slowness***, especially for predicting large datasets like ours, and because of its inability to manage a lot of features (here 37).\n",
    "\n",
    "The method that we are going to study next doesn't have these drawbacks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Linear models : SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "We are going to deal with a linear model, that realize predictions with a linear functions of the input features.\n",
    "We know that linear models are good for very large datasets, with large dimensions, that is our case.\n",
    "\n",
    "We have chosen SVM, one of these linear models, the one we've seen the most detail of in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this model small=0: we work with all the data because it is faster than KNN\n",
    "* Here, the standardization of our data is very important. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of the data\n",
    "\n",
    "mean_on_train=X_train.mean(axis=0)\n",
    "std_on_train=X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled=(X_train-mean_on_train)/std_on_train\n",
    "X_test_scaled=(X_test-mean_on_train)/std_on_train\n",
    "X_exam_scaled=(X_exam-mean_on_train)/std_on_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Default parameters \n",
    "\n",
    "svm1=LinearSVC()\n",
    "svm1.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981030790742244"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm1.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=svm1.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.80544912608089 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99301814e-01 6.98186189e-04]\n",
      " [3.41289146e-02 9.65871085e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=svm1.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.title(\"Confusion matrix : SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilan : \n",
    "\n",
    "Dataset| Scores \n",
    "- |-: \n",
    "training set  | 99,81%\n",
    "test set | 99,80% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "With default parameters, we were already getting very interesting scores.It's again a perfect for label 0, and we have improved our prediction of label 1.\n",
    "\n",
    "We quickly understood that a sufficiently complex model was able to obtain scores higher than 99% on the test set, we would have to go for scores higher than 99.8% to stay in the competition. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the best hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the first time, we're going to go deeper into this model,by looking for the best hyper-parameters.\n",
    "\n",
    "We are going to play on two parameters : \n",
    " * C : Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    " * class-weight : Set the parameter C of class i to class_weight[i]*C for SVC. We see if we change stg by giving more weight to the minority class.\n",
    " \n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'C':[0.01,0.1,1],\n",
    "           'class_weight': [{0:1,1:1},{0:1,1:5},{0:1,1:15}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we search the best combination of these two parameters by doing a GridSearch with cross-validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/paul/.local/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 0.1, 1],\n",
       "                         'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 5},\n",
       "                                          {0: 1, 1: 15}]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(LinearSVC(), parameters)\n",
    "grid.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'class_weight': {0: 1, 1: 1}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corresponding score : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9977985661648525"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "It's weird but our best score is inferior to the score we get without doing the gridsearch. With this model, tuning the parameters doesn't change a lot our scores. Also, the best parameter 'class_weights\" is {0:1,1:1}, ie equal weights for each class. It means that we don't really need to adapt our algorithm to the fact that the class are unbalanced. Both class must be sufficiently weel separated. \n",
    "\n",
    "The big advantage of linear models is that they are very fast in terms of prediction and training. They are also able to adapt to large datasets like ours. \n",
    "\n",
    "So we managed to improve our score over KNN. \n",
    "However, we are still far from the 0.9985 we are now aiming for. \n",
    "In order not to waste time, and because we are eager to train more complex models, we will move directly to the next step.\n",
    "\n",
    "Idea we could have done to improve this step: \n",
    "- do some regularization with Ridge and LASSO (but it seems useless because we don't really overfit)\n",
    "- try SVM with kernels\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT : \n",
    "submit(model=svm1,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "We need a more complex classifier so that our score goes up to 0,9985.\n",
    "For our neural network, we chose to use the sklearn.neural_network library and the MLPClassifier model, that is very quick.\n",
    "\n",
    "Let's do a first try without taking care of the parameters : \n",
    "\n",
    "(Again we work with the scaled version of our data)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(15,),verbose=1,max_iter=500,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03063585\n",
      "Iteration 2, loss = 0.00673447\n",
      "Iteration 3, loss = 0.00594956\n",
      "Iteration 4, loss = 0.00560891\n",
      "Iteration 5, loss = 0.00536448\n",
      "Iteration 6, loss = 0.00522307\n",
      "Iteration 7, loss = 0.00510961\n",
      "Iteration 8, loss = 0.00505204\n",
      "Iteration 9, loss = 0.00499033\n",
      "Iteration 10, loss = 0.00494338\n",
      "Iteration 11, loss = 0.00488052\n",
      "Iteration 12, loss = 0.00484259\n",
      "Iteration 13, loss = 0.00480436\n",
      "Iteration 14, loss = 0.00478234\n",
      "Iteration 15, loss = 0.00473177\n",
      "Iteration 16, loss = 0.00469255\n",
      "Iteration 17, loss = 0.00464473\n",
      "Iteration 18, loss = 0.00461066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984550850192137"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=mlp.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.82359964493047 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99540434e-01 4.59565593e-04]\n",
      " [3.54211006e-02 9.64578899e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=mlp.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.title(\"Confusion matrix : MLP Classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilan : \n",
    "\n",
    "Dataset| Scores \n",
    "- |-: \n",
    "training set  | 99,84%\n",
    "test set | 99,82% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without doing any gridsearch, just by testing a MLP with one layer and 15 neurons, we reach very good scores.\n",
    "\n",
    "\n",
    "So we thought it was a model to dig. \n",
    "The big advantage of this model compared to the models we'll see later is that the training was very fast. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have tested various parameters. \n",
    "We played with: \n",
    "- hidden_layer_sizes : the number of layer and neurons per layer\n",
    "- the learning rate : constant or invscaling (gradually decreases the learning rate at each epoch)\n",
    "- tol: stopping criterion, if the score has not increased by at least tol, the training stops (we change it by hand, we expect to improve the training with a very small tol)\n",
    "\n",
    "The problem is that the parameter tuning didn't change much. \n",
    "The few times we got a score on the test set, above 99.86%, we got \"only\" 99.80 when submitting our model. \n",
    "Another defect is that the tol parameter can't be as small as we want. The training lasts a maximum of 70 epochs. We can't get an accuracy as small as we want to the thousandth, while every decimal place is important in this project. \n",
    "\n",
    "Paradoxically, the best score we submitted comes from a model whose parameters were obtained \"by hand\", i.e. without gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 40.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hidden_layer_sizes is  (130, 50)  with an average validation score equal to  0.9980443993179756\n",
      "It s better to work with leatning rate = invscaling\n",
      "The test score is 0.9977765677466195\n"
     ]
    }
   ],
   "source": [
    "res=[]\n",
    "for i in range(10,200,20):\n",
    "    for j in range(10,100,10):\n",
    "        res.append((i,j))\n",
    "    res.append((i,))\n",
    "\n",
    "param = {\n",
    "    'hidden_layer_sizes': res,\n",
    "    'learning_rate':['constant','invscaling'],\n",
    "    }\n",
    "\n",
    "model = MLPClassifier(tol=0.00001,max_iter=300)\n",
    "\n",
    "grid = RandomizedSearchCV(model, param, n_iter=50, cv=5, n_jobs=-1,verbose=1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('The best hidden_layer_sizes is ', grid.best_params_.get('hidden_layer_sizes'),' with an average validation score equal to ', grid.best_score_)\n",
    "print('It s better to work with leatning rate =', grid.best_params_.get('learning_rate'))\n",
    "\n",
    "# Let's now use the best model to assess the test score\n",
    "BestModel=grid.best_estimator_\n",
    "print('The test score is', BestModel.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(130,5),learning_rate='invscaling',verbose=1,max_iter=500,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.04328032\n",
      "Iteration 2, loss = 0.00828405\n",
      "Iteration 3, loss = 0.00686279\n",
      "Iteration 4, loss = 0.00601021\n",
      "Iteration 5, loss = 0.00533653\n",
      "Iteration 6, loss = 0.00511262\n",
      "Iteration 7, loss = 0.00446764\n",
      "Iteration 8, loss = 0.00445541\n",
      "Iteration 9, loss = 0.00431391\n",
      "Iteration 10, loss = 0.00373403\n",
      "Iteration 11, loss = 0.00337345\n",
      "Iteration 12, loss = 0.00317996\n",
      "Iteration 13, loss = 0.00285204\n",
      "Iteration 14, loss = 0.00268906\n",
      "Iteration 15, loss = 0.00245521\n",
      "Iteration 16, loss = 0.00252386\n",
      "Iteration 17, loss = 0.00236168\n",
      "Iteration 18, loss = 0.00235667\n",
      "Iteration 19, loss = 0.00172009\n",
      "Iteration 20, loss = 0.00166245\n",
      "Iteration 21, loss = 0.00134417\n",
      "Iteration 22, loss = 0.00124160\n",
      "Iteration 23, loss = 0.00113403\n",
      "Iteration 24, loss = 0.00100340\n",
      "Iteration 25, loss = 0.00096585\n",
      "Iteration 26, loss = 0.00090362\n",
      "Iteration 27, loss = 0.00077585\n",
      "Iteration 28, loss = 0.00059776\n",
      "Iteration 29, loss = 0.00145707\n",
      "Iteration 30, loss = 0.00182690\n",
      "Iteration 31, loss = 0.00089151\n",
      "Iteration 32, loss = 0.00055783\n",
      "Iteration 33, loss = 0.00040079\n",
      "Iteration 34, loss = 0.00032481\n",
      "Iteration 35, loss = 0.00025980\n",
      "Iteration 36, loss = 0.00032639\n",
      "Iteration 37, loss = 0.00060468\n",
      "Iteration 38, loss = 0.00098223\n",
      "Iteration 39, loss = 0.00035871\n",
      "Iteration 40, loss = 0.00030996\n",
      "Iteration 41, loss = 0.00033949\n",
      "Iteration 42, loss = 0.00018705\n",
      "Iteration 43, loss = 0.00015245\n",
      "Iteration 44, loss = 0.00118321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(130, 5), learning_rate='invscaling',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996535809670678"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978219439150559"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=mlp.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99175073e-01 8.24926935e-04]\n",
      " [3.70145631e-02 9.62985437e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The problem is that the parameter tuning didn't change much. \n",
    "\n",
    "The few times we got a score on the test set above 99.86%, we got \"only\" 99.80 when submitting our model. \n",
    "Another defect is that the tol parameter can't be as small as we want. The training lasts a maximum of 70 epochs. We can't get an accuracy as small as we want to the thousandth, while every decimal place is important in this project. \n",
    "\n",
    "Paradoxically, the best score we submitted comes from a model whose parameters were obtained \"by hand\", i.e. without gridsearch.\n",
    "\n",
    "In an attempt to further improve our score, we decided to learn more about the models that frequently win machine learning competitions. \n",
    "That's how we found a model that frequently seemed to be above the others, called xgboost. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT : \n",
    "submit(model=mlp,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- XGBOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***What is XGBoost?***\n",
    "\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework.\n",
    "\n",
    "Its in fact an optimized gradient boosting algorithm through parallel processing, tree-pruning, handling missing values and regularization to avoid overfitting. XGBoost algorithm was developed as a research project at the University of Washington by Tianqi Chen and Carlos Guestrin. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we gonna test it with default parameters. We don't need to have our data scaled here, so we use X_train and not X_train scaled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification done in 69.51561117172241s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "boost = XGBClassifier()\n",
    "boost.fit(X_train,y_train)\n",
    "print(\"Classification done in \"+str(time() - t0)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999804441141673"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=boost.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.8896788776173 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score is the best we've had since the beginning so we'll try to submit it right away and see what it says about the data to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT\n",
    "submit(model=boost,X_exam=X_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE OBTAINED : ***0.998423889852***. \n",
    "\n",
    "This is good but we can do better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99578732e-01 4.21268460e-04]\n",
      " [1.86986926e-02 9.81301307e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=boost.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this model, winner in many Kaggle competitions, allowed us to get good scores directly. It's the first time we achieve such score on the test sets, and especially the first time our prediction on label 1 reach 0.98.\n",
    "\n",
    "\n",
    "However, xgboost has two major drawbacks: \n",
    "\n",
    "- its training time: on our computers, a training on all training observations could take up to 10 minutes. \n",
    "\n",
    "- its number of hyper-parameters to be adjusted : \n",
    "By reading on the internet tips for tuning the hyper-parameters of the xgboost, we have seen that the number of parameters to play with is 6. \n",
    "\n",
    "source : https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of parameter that we are going to examine : \n",
    "\n",
    "* max_depth : Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "\n",
    "* gamma : Minimum loss reduction required to make a further partition on a leaf node of the tree. \n",
    "\n",
    "* n_estimators : very important. The number of boosting stages to perform.\n",
    "\n",
    "* learning_rate : learning rate shrinks the contribution of each tree by learning_rate.\n",
    "\n",
    "* subsample : Subsample ratio of the training instance.\n",
    "\n",
    "* colsample_bytree : subsample ratio of columns when constructing each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_fixed={'objective':'binary:logistic','silent':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dist_grid={\n",
    "    'max_depth':range(3,10,2),\n",
    "    'gamma':[0,0.5,1],\n",
    "    'n_estimators':randint(30,500),\n",
    "    'learning_rate':uniform(),\n",
    "    'subsample':uniform(),\n",
    "    'colsample_bytree':uniform()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing 6 values for each of the parameters, we obtain 6=46,656 possibilities. If we count 5 minutes per iteration, we get 233,280 minutes, 3888 hours, 162 days. And still, we did not take into account that the cross validation practiced in the gridsearch took even more time than a simple training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, it was totally impossible to test all possible parameters. \n",
    "That's why we chose to use a RandomizedGridSearchCV. With this type of approach, we choose the number of possibilities we will test. \n",
    "These will be randomly selected among the possibilities that we have entered as input. \n",
    "So we are not sure to get a maximum overall score, but the best combination of parameters will probably give a very good score. \n",
    "In terms of the number of possibilities to test, we've chosen to test 50, which is enough to keep the training running for a long afternoon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the correspondig code. It take one night to make the 50 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_grid=RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed,seed=seed),param_distributions=params_dist_grid,\n",
    "n_iter=50,\n",
    "cv=3,\n",
    "scoring='accuracy',\n",
    "random_state=seed,\n",
    "verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.997, total=   4.3s\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.996, total=   4.2s\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.997, total=   4.2s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   12.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  39.4s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   52.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  39.7s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  40.0s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.998, total=  16.0s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.999, total=  16.0s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.999, total=  20.3s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  31.6s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n",
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  28.2s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n",
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  29.0s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  14.6s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  14.4s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  14.8s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  42.1s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  41.1s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  41.6s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.997, total=   9.7s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.997, total=   9.7s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.998, total=   9.7s\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  55.1s\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  53.9s\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  55.1s\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total=  58.0s\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total=  57.6s\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total=  59.0s\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total=  56.9s\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total=  56.8s\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total=  56.9s\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n",
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n",
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  23.7s\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  23.8s\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  24.1s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.998, total=  23.1s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.998, total=  23.0s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.999, total=  23.0s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=  10.8s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=  10.9s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=16.1min\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  28.9s\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  28.7s\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  29.4s\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total=  57.8s\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total=  56.9s\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total=  57.1s\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n",
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  42.4s\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  42.5s\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n",
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  43.5s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.997, total=   6.4s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.997, total=   6.4s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.997, total=   6.5s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  11.9s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  11.8s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  11.7s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.4s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.3s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.4s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  34.5s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  34.5s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  34.4s\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.998, total=  16.0s\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.998, total=  16.0s\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.998, total=  16.0s\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.998, total=  36.2s\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.999, total=12.5min\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.999, total=  38.1s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.998, total=   6.6s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n",
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.998, total=   6.7s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n",
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.999, total=   6.6s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.998, total=  24.5s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.998, total=  24.1s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.999, total=  24.3s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  12.1s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  12.0s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  12.3s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.997, total=  11.1s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.997, total=  11.1s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.997, total=  11.4s\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.5min\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.5min\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.5min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  38.5s\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  38.3s\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  39.2s\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n",
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  51.4s\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n",
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  51.9s\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  51.9s\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.998, total=66.2min\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.997, total=  10.5s\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.997, total=  10.4s\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.997, total=  10.5s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  41.6s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  41.6s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  42.0s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  12.5s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  12.6s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  13.0s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.998, total=  31.8s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.998, total=  34.5s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.999, total=  32.2s\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.6min\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.998, total=  24.6s\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.998, total=  24.8s\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.999, total=  25.1s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n",
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  54.5s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  55.1s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n",
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  55.6s\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.998, total=  17.4s\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.998, total=  17.4s\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.997, total=  17.4s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  48.7s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  49.5s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  50.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 199.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n...\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f049e0eccf8>,\n",
       "                                        'max_depth': range(3, 10, 2),\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f049e0ecba8>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f049e0ecf28>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=342, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988126784811241"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters found are : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5213285655977811,\n",
       " 'gamma': 1,\n",
       " 'learning_rate': 0.12245745743134928,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 448,\n",
       " 'subsample': 0.48831719352338554}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we test this model, considered to be the best one : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBClassifier(colsample_bytree= 0.5213285655977811,\n",
    " gamma= 1,\n",
    " learning_rate= 0.12245745743134928,\n",
    " max_depth= 5,\n",
    " n_estimators= 448,\n",
    " subsample= 0.48831719352338554,objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5213285655977811, gamma=1,\n",
       "              gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.12245745743134928, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=448, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=0.48831719352338554,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999319357473455"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT : \n",
    "submit(model=clf,X_exam=X_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to improve again this score, so we try the RandomizedSearchCV another night with twice more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_grid=RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(**params_fixed,seed=seed),param_distributions=params_dist_grid,\n",
    "n_iter=100,\n",
    "cv=3,\n",
    "scoring='accuracy',\n",
    "random_state=seed,\n",
    "verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.997, total=   3.3s\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.997, total=   3.3s\n",
      "[CV] colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.06503439684192913, gamma=0, learning_rate=0.24756150723102166, max_depth=7, n_estimators=34, subsample=0.11848249237448605, score=0.997, total=   3.3s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  36.6s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   46.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  38.5s\n",
      "[CV] colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.13214054942810016, gamma=0, learning_rate=0.4325346125891868, max_depth=3, n_estimators=457, subsample=0.8942723823370169, score=0.999, total=  38.5s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.998, total=  16.4s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.999, total=  15.8s\n",
      "[CV] colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.1523931947190449, gamma=1, learning_rate=0.23096728629607655, max_depth=7, n_estimators=91, subsample=0.7099300190073073, score=0.999, total=  15.9s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  27.5s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n",
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  27.8s\n",
      "[CV] colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573 \n",
      "[CV]  colsample_bytree=0.22187963515640408, gamma=1, learning_rate=0.3807697564898246, max_depth=7, n_estimators=142, subsample=0.8058014316376573, score=0.999, total=  28.5s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  14.6s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  15.0s\n",
      "[CV] colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399 \n",
      "[CV]  colsample_bytree=0.4636309538821305, gamma=0, learning_rate=0.7652628330253548, max_depth=3, n_estimators=217, subsample=0.005635524386628399, score=0.997, total=  15.4s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  45.9s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  43.9s\n",
      "[CV] colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213 \n",
      "[CV]  colsample_bytree=0.3484693847948471, gamma=0.5, learning_rate=0.501367277763467, max_depth=3, n_estimators=344, subsample=0.7446963541453213, score=0.999, total=  43.9s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.998, total=  10.3s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.997, total=  10.2s\n",
      "[CV] colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998 \n",
      "[CV]  colsample_bytree=0.027059952336016435, gamma=0.5, learning_rate=0.32181898059099534, max_depth=7, n_estimators=106, subsample=0.1430695313368998, score=0.998, total=  10.1s\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926 \n",
      "[CV]  colsample_bytree=0.6052416274824561, gamma=0, learning_rate=0.6050492440098373, max_depth=7, n_estimators=304, subsample=0.7395162785706926, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  56.1s\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  55.6s\n",
      "[CV] colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364 \n",
      "[CV]  colsample_bytree=0.3798729645059653, gamma=0, learning_rate=0.2244110761611232, max_depth=9, n_estimators=212, subsample=0.38626895174139364, score=0.999, total=  55.9s\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total= 1.0min\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total= 1.0min\n",
      "[CV] colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556 \n",
      "[CV]  colsample_bytree=0.6081741773955259, gamma=0, learning_rate=0.3242569496604357, max_depth=3, n_estimators=487, subsample=0.16575363219645556, score=0.998, total= 1.0min\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663 \n",
      "[CV]  colsample_bytree=0.34825342627224587, gamma=0, learning_rate=0.4185815141367779, max_depth=3, n_estimators=488, subsample=0.8780483709609663, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n",
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n",
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4288656296016934, gamma=0.5, learning_rate=0.6730164898324128, max_depth=5, n_estimators=410, subsample=0.7248087016755762, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  24.7s\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  24.9s\n",
      "[CV] colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579 \n",
      "[CV]  colsample_bytree=0.0017306007327145823, gamma=0.5, learning_rate=0.05315918465055469, max_depth=9, n_estimators=205, subsample=0.8061810315662579, score=0.997, total=  25.2s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.998, total=  24.4s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.999, total=  24.5s\n",
      "[CV] colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241 \n",
      "[CV]  colsample_bytree=0.0652058663329057, gamma=0.5, learning_rate=0.3009542371416952, max_depth=5, n_estimators=215, subsample=0.7182879010530241, score=0.999, total=  24.5s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=  11.7s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=  11.8s\n",
      "[CV] colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927 \n",
      "[CV]  colsample_bytree=0.03736425297203316, gamma=1, learning_rate=0.34508603000232396, max_depth=3, n_estimators=149, subsample=0.3515989871516927, score=0.998, total=  11.7s\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608 \n",
      "[CV]  colsample_bytree=0.28640275096467005, gamma=0.5, learning_rate=0.13625268915862287, max_depth=5, n_estimators=375, subsample=0.7122370715991608, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  28.6s\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  28.5s\n",
      "[CV] colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143 \n",
      "[CV]  colsample_bytree=0.11584888265940785, gamma=0, learning_rate=0.4908537989581572, max_depth=7, n_estimators=217, subsample=0.21808623249143, score=0.998, total=  28.7s\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024 \n",
      "[CV]  colsample_bytree=0.6104278565642697, gamma=1, learning_rate=0.19229938260169954, max_depth=3, n_estimators=384, subsample=0.9695258738383024, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013 \n",
      "[CV]  colsample_bytree=0.4418555802707862, gamma=1, learning_rate=0.838802169791344, max_depth=9, n_estimators=483, subsample=0.34916312744720013, score=0.998, total= 1.6min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324 \n",
      "[CV]  colsample_bytree=0.6468232104916526, gamma=0.5, learning_rate=0.5599867682778354, max_depth=7, n_estimators=376, subsample=0.8247083447312324, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n",
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  43.7s\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  43.7s\n",
      "[CV] colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981 \n",
      "[CV]  colsample_bytree=0.4697145869577216, gamma=0.5, learning_rate=0.39720907308977726, max_depth=3, n_estimators=312, subsample=0.9607885510753981, score=0.999, total=  43.5s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.997, total=   6.5s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.998, total=   6.4s\n",
      "[CV] colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438 \n",
      "[CV]  colsample_bytree=0.1807105983444972, gamma=0.5, learning_rate=0.7116905005504024, max_depth=7, n_estimators=43, subsample=0.12476164013176438, score=0.997, total=   6.5s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  12.3s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  12.2s\n",
      "[CV] colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037 \n",
      "[CV]  colsample_bytree=0.04489508721875779, gamma=0.5, learning_rate=0.3573079777273209, max_depth=7, n_estimators=104, subsample=0.5565968240145037, score=0.998, total=  12.4s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.9s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.8s\n",
      "[CV] colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166 \n",
      "[CV]  colsample_bytree=0.5378305425082532, gamma=0.5, learning_rate=0.07486337619698258, max_depth=5, n_estimators=50, subsample=0.419807612168166, score=0.998, total=  11.8s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  36.3s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  36.3s\n",
      "[CV] colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917 \n",
      "[CV]  colsample_bytree=0.08027764806449922, gamma=0, learning_rate=0.5816739095805397, max_depth=3, n_estimators=431, subsample=0.43419038829354917, score=0.998, total=  36.6s\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769 \n",
      "[CV]  colsample_bytree=0.8443575182198271, gamma=0, learning_rate=0.7856293762743507, max_depth=7, n_estimators=192, subsample=0.7530818233092769, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.998, total=  16.9s\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.999, total=  16.8s\n",
      "[CV] colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116 \n",
      "[CV]  colsample_bytree=0.42208030371369953, gamma=0, learning_rate=0.6831122329710866, max_depth=3, n_estimators=120, subsample=0.49261723921786116, score=0.999, total=  16.8s\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956 \n",
      "[CV]  colsample_bytree=0.8239347020567251, gamma=0, learning_rate=0.46000569578319994, max_depth=7, n_estimators=239, subsample=0.3321379188544956, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.998, total=  37.7s\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.999, total=  38.9s\n",
      "[CV] colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456 \n",
      "[CV]  colsample_bytree=0.7392011452227608, gamma=0, learning_rate=0.7943107818388505, max_depth=7, n_estimators=108, subsample=0.5403080029773456, score=0.999, total=  38.7s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.998, total=   7.1s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n",
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.998, total=   7.1s\n",
      "[CV] colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703 \n",
      "[CV]  colsample_bytree=0.7494207571997938, gamma=1, learning_rate=0.5669082329780527, max_depth=3, n_estimators=35, subsample=0.8936616121288703, score=0.999, total=   7.1s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.998, total=  26.0s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.998, total=  26.9s\n",
      "[CV] colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917 \n",
      "[CV]  colsample_bytree=0.1233781606164811, gamma=0.5, learning_rate=0.09772802614862519, max_depth=3, n_estimators=295, subsample=0.32162421002224917, score=0.999, total=  25.9s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  13.1s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  12.8s\n",
      "[CV] colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184 \n",
      "[CV]  colsample_bytree=0.1473000060656997, gamma=0.5, learning_rate=0.13448222256392894, max_depth=5, n_estimators=106, subsample=0.23774042930082184, score=0.998, total=  12.8s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.997, total=  11.2s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.996, total=  11.2s\n",
      "[CV] colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213 \n",
      "[CV]  colsample_bytree=0.9670359633400014, gamma=0, learning_rate=0.7056816909331856, max_depth=5, n_estimators=61, subsample=0.01977714403091213, score=0.997, total=  11.0s\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.6min\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.5min\n",
      "[CV] colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102 \n",
      "[CV]  colsample_bytree=0.2180407029928415, gamma=0.5, learning_rate=0.07812750650828248, max_depth=9, n_estimators=415, subsample=0.518517898052102, score=0.999, total= 1.5min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185 \n",
      "[CV]  colsample_bytree=0.41559925955532984, gamma=1, learning_rate=0.7698928944238359, max_depth=9, n_estimators=328, subsample=0.22604362169550185, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  39.5s\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  39.8s\n",
      "[CV] colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104 \n",
      "[CV]  colsample_bytree=0.5642240482168264, gamma=0.5, learning_rate=0.09939965650812232, max_depth=9, n_estimators=123, subsample=0.28602526178423104, score=0.999, total=  39.8s\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914 \n",
      "[CV]  colsample_bytree=0.6895767510518857, gamma=0.5, learning_rate=0.0011319754648878577, max_depth=5, n_estimators=329, subsample=0.37315429901325914, score=0.998, total= 1.3min\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n",
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  53.3s\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n",
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  52.9s\n",
      "[CV] colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.45294600144107167, gamma=1, learning_rate=0.08303834961595746, max_depth=7, n_estimators=187, subsample=0.6069127728741993, score=0.999, total=  53.0s\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962 \n",
      "[CV]  colsample_bytree=0.7327546305008223, gamma=0.5, learning_rate=0.692803142146249, max_depth=7, n_estimators=180, subsample=0.705851693379962, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.998, total=  11.2s\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.997, total=  11.2s\n",
      "[CV] colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645 \n",
      "[CV]  colsample_bytree=0.05362154980326561, gamma=0, learning_rate=0.7980698940293289, max_depth=3, n_estimators=158, subsample=0.17004133125997645, score=0.998, total=  11.1s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  43.6s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  43.7s\n",
      "[CV] colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174 \n",
      "[CV]  colsample_bytree=0.07134898268568757, gamma=0.5, learning_rate=0.35233232505199596, max_depth=5, n_estimators=458, subsample=0.22387461076329174, score=0.998, total=  43.8s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  12.9s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  13.2s\n",
      "[CV] colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535 \n",
      "[CV]  colsample_bytree=0.5830420267513081, gamma=0, learning_rate=0.1407773526305579, max_depth=3, n_estimators=114, subsample=0.06530708638295535, score=0.998, total=  13.0s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.998, total=  33.4s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.999, total=  33.2s\n",
      "[CV] colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053 \n",
      "[CV]  colsample_bytree=0.1272012299182168, gamma=0.5, learning_rate=0.7365916997846382, max_depth=5, n_estimators=259, subsample=0.5938153837167053, score=0.999, total=  33.3s\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554 \n",
      "[CV]  colsample_bytree=0.5213285655977811, gamma=1, learning_rate=0.12245745743134928, max_depth=5, n_estimators=448, subsample=0.48831719352338554, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574 \n",
      "[CV]  colsample_bytree=0.5241718165563152, gamma=0.5, learning_rate=0.019013169365516558, max_depth=3, n_estimators=463, subsample=0.6098711368955574, score=0.998, total= 1.2min\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.998, total=  24.7s\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.999, total=  24.6s\n",
      "[CV] colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983 \n",
      "[CV]  colsample_bytree=0.671301928197165, gamma=0.5, learning_rate=0.5467452756716188, max_depth=3, n_estimators=140, subsample=0.5648319298748983, score=0.999, total=  24.7s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n",
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  54.4s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  53.9s\n",
      "[CV] colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632 \n",
      "[CV]  colsample_bytree=0.919421811544759, gamma=1, learning_rate=0.9622594737743404, max_depth=5, n_estimators=158, subsample=0.6372091818441632, score=0.998, total=  54.4s\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713 \n",
      "[CV]  colsample_bytree=0.6754086694441321, gamma=0, learning_rate=0.22800333163252395, max_depth=9, n_estimators=165, subsample=0.4357666773827713, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.997, total=  17.6s\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.998, total=  17.4s\n",
      "[CV] colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052 \n",
      "[CV]  colsample_bytree=0.15852842041802295, gamma=0.5, learning_rate=0.643530100011603, max_depth=3, n_estimators=221, subsample=0.10669012117628052, score=0.998, total=  17.5s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  49.0s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  49.4s\n",
      "[CV] colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707 \n",
      "[CV]  colsample_bytree=0.025980915983675024, gamma=0, learning_rate=0.4832152000966258, max_depth=7, n_estimators=450, subsample=0.4628262226680707, score=0.998, total=  49.2s\n",
      "[CV] colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778 \n",
      "[CV]  colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778, score=0.997, total=  26.8s\n",
      "[CV] colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778 \n",
      "[CV]  colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778, score=0.997, total=  26.7s\n",
      "[CV] colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778 \n",
      "[CV]  colsample_bytree=0.12936438191081456, gamma=0, learning_rate=0.6925902605666766, max_depth=5, n_estimators=271, subsample=0.13207322963848778, score=0.997, total=  27.0s\n",
      "[CV] colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742 \n",
      "[CV]  colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742, score=0.998, total=  58.6s\n",
      "[CV] colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742 \n",
      "[CV]  colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742, score=0.999, total=  59.2s\n",
      "[CV] colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742 \n",
      "[CV]  colsample_bytree=0.9023735729428712, gamma=0.5, learning_rate=0.16459096754349534, max_depth=7, n_estimators=214, subsample=0.1149135131077742, score=0.999, total=  59.2s\n",
      "[CV] colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075 \n",
      "[CV]  colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075 \n",
      "[CV]  colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075 \n",
      "[CV]  colsample_bytree=0.7399930949466056, gamma=1, learning_rate=0.7564334698000733, max_depth=5, n_estimators=305, subsample=0.2298970770975075, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272 \n",
      "[CV]  colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272 \n",
      "[CV]  colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272, score=0.999, total= 1.8min\n",
      "[CV] colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272 \n",
      "[CV]  colsample_bytree=0.7419625598864609, gamma=0, learning_rate=0.19782370344184108, max_depth=9, n_estimators=404, subsample=0.14492255521087272, score=0.999, total= 1.8min\n",
      "[CV] colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761 \n",
      "[CV]  colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761 \n",
      "[CV]  colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761, score=0.999, total= 1.4min\n",
      "[CV] colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761 \n",
      "[CV]  colsample_bytree=0.33473414668950685, gamma=0, learning_rate=0.026090948956925764, max_depth=7, n_estimators=375, subsample=0.3085565577280761, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251, score=0.996, total=   7.0s\n",
      "[CV] colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251 \n",
      "[CV]  colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251, score=0.995, total=   6.9s\n",
      "[CV] colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251 \n",
      "[CV]  colsample_bytree=0.09712926011751544, gamma=1, learning_rate=0.026293094084396507, max_depth=7, n_estimators=59, subsample=0.08470617912256251, score=0.995, total=   6.8s\n",
      "[CV] colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743 \n",
      "[CV]  colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743, score=0.999, total=  41.1s\n",
      "[CV] colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743 \n",
      "[CV]  colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743, score=0.999, total=  40.6s\n",
      "[CV] colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743 \n",
      "[CV]  colsample_bytree=0.4660191122328683, gamma=0.5, learning_rate=0.2721599325974995, max_depth=5, n_estimators=184, subsample=0.7718717535091743, score=0.999, total=  41.2s\n",
      "[CV] colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266 \n",
      "[CV]  colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266, score=0.998, total=  50.7s\n",
      "[CV] colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266 \n",
      "[CV]  colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266, score=0.998, total=  50.5s\n",
      "[CV] colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266 \n",
      "[CV]  colsample_bytree=0.0196350531903301, gamma=0, learning_rate=0.5608552327112024, max_depth=9, n_estimators=438, subsample=0.8308693569436266, score=0.998, total=  50.8s\n",
      "[CV] colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972 \n",
      "[CV]  colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972, score=0.998, total=  51.6s\n",
      "[CV] colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972 \n",
      "[CV]  colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972, score=0.998, total=  52.5s\n",
      "[CV] colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972 \n",
      "[CV]  colsample_bytree=0.3022201220854588, gamma=0, learning_rate=0.8826391501054447, max_depth=5, n_estimators=402, subsample=0.2049291021815972, score=0.998, total=  52.2s\n",
      "[CV] colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562 \n",
      "[CV]  colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562, score=0.997, total=  21.5s\n",
      "[CV] colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562 \n",
      "[CV]  colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562, score=0.997, total=  21.7s\n",
      "[CV] colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562 \n",
      "[CV]  colsample_bytree=0.3807465201080452, gamma=0.5, learning_rate=0.6852319036671645, max_depth=3, n_estimators=227, subsample=0.0731181499958562, score=0.997, total=  21.6s\n",
      "[CV] colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774 \n",
      "[CV]  colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774, score=0.997, total=  40.5s\n",
      "[CV] colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774 \n",
      "[CV]  colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774, score=0.997, total=  40.9s\n",
      "[CV] colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774 \n",
      "[CV]  colsample_bytree=0.17699034320789264, gamma=1, learning_rate=0.7904219886137076, max_depth=5, n_estimators=469, subsample=0.09950285387090774, score=0.997, total=  41.2s\n",
      "[CV] colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863 \n",
      "[CV]  colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863, score=0.999, total=  31.2s\n",
      "[CV] colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863 \n",
      "[CV]  colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863, score=0.999, total=  30.8s\n",
      "[CV] colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863 \n",
      "[CV]  colsample_bytree=0.6453814641206962, gamma=0, learning_rate=0.6489622209916911, max_depth=5, n_estimators=119, subsample=0.7172982319058863, score=0.999, total=  31.4s\n",
      "[CV] colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481 \n",
      "[CV]  colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481, score=0.998, total=  10.3s\n",
      "[CV] colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481 \n",
      "[CV]  colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481, score=0.998, total=  10.3s\n",
      "[CV] colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481 \n",
      "[CV]  colsample_bytree=0.21862382069258146, gamma=0.5, learning_rate=0.15001375427002706, max_depth=3, n_estimators=102, subsample=0.3236587597229481, score=0.999, total=  10.3s\n",
      "[CV] colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378 \n",
      "[CV]  colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378 \n",
      "[CV]  colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378, score=0.999, total= 1.9min\n",
      "[CV] colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.8997330149392108, gamma=0.5, learning_rate=0.3835247744746083, max_depth=5, n_estimators=356, subsample=0.7052102240395378, score=0.999, total= 2.0min\n",
      "[CV] colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892 \n",
      "[CV]  colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892, score=0.997, total=  26.1s\n",
      "[CV] colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892 \n",
      "[CV]  colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892, score=0.997, total=  27.4s\n",
      "[CV] colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892 \n",
      "[CV]  colsample_bytree=0.8274594348493765, gamma=0, learning_rate=0.9807421345062718, max_depth=7, n_estimators=357, subsample=0.007095876549151892, score=0.997, total=  27.1s\n",
      "[CV] colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172 \n",
      "[CV]  colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172, score=0.999, total=  36.6s\n",
      "[CV] colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172 \n",
      "[CV]  colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172, score=0.999, total=  36.4s\n",
      "[CV] colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172 \n",
      "[CV]  colsample_bytree=0.20232884924216632, gamma=0, learning_rate=0.2702093627098191, max_depth=5, n_estimators=247, subsample=0.83911487102172, score=0.999, total=  36.3s\n",
      "[CV] colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638 \n",
      "[CV]  colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638 \n",
      "[CV]  colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638, score=0.999, total= 1.2min\n",
      "[CV] colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638 \n",
      "[CV]  colsample_bytree=0.7589294511785274, gamma=0.5, learning_rate=0.4359531294299118, max_depth=3, n_estimators=410, subsample=0.931964856164638, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389 \n",
      "[CV]  colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389, score=0.999, total= 1.8min\n",
      "[CV] colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389 \n",
      "[CV]  colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389, score=0.999, total= 1.8min\n",
      "[CV] colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389 \n",
      "[CV]  colsample_bytree=0.6353029959551116, gamma=1, learning_rate=0.4597663311041704, max_depth=5, n_estimators=446, subsample=0.4719941047090389, score=0.999, total= 1.8min\n",
      "[CV] colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445 \n",
      "[CV]  colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445, score=0.999, total= 1.6min\n",
      "[CV] colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445 \n",
      "[CV]  colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445, score=0.999, total= 1.6min\n",
      "[CV] colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445 \n",
      "[CV]  colsample_bytree=0.631714367902491, gamma=0.5, learning_rate=0.08673527024268302, max_depth=5, n_estimators=398, subsample=0.4025895046450445, score=0.999, total= 1.6min\n",
      "[CV] colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284 \n",
      "[CV]  colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284, score=0.998, total= 1.4min\n",
      "[CV] colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284 \n",
      "[CV]  colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284, score=0.998, total= 1.4min\n",
      "[CV] colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284 \n",
      "[CV]  colsample_bytree=0.370169261051031, gamma=1, learning_rate=0.23649191416687532, max_depth=9, n_estimators=458, subsample=0.157342950917284, score=0.999, total= 1.4min\n",
      "[CV] colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009 \n",
      "[CV]  colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009 \n",
      "[CV]  colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009, score=0.999, total= 1.3min\n",
      "[CV] colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009 \n",
      "[CV]  colsample_bytree=0.3940255142601945, gamma=0, learning_rate=0.6478858456370922, max_depth=9, n_estimators=430, subsample=0.7900397119400009, score=0.999, total= 1.4min\n",
      "[CV] colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514 \n",
      "[CV]  colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514, score=0.999, total=  37.6s\n",
      "[CV] colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514 \n",
      "[CV]  colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514, score=0.999, total=  37.1s\n",
      "[CV] colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514 \n",
      "[CV]  colsample_bytree=0.415071774582214, gamma=0, learning_rate=0.16469217470793096, max_depth=5, n_estimators=181, subsample=0.8608607124804514, score=0.999, total=  37.4s\n",
      "[CV] colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755 \n",
      "[CV]  colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755, score=0.999, total=  23.9s\n",
      "[CV] colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755, score=0.999, total=  23.5s\n",
      "[CV] colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755 \n",
      "[CV]  colsample_bytree=0.33627139494857383, gamma=0.5, learning_rate=0.24389578673746937, max_depth=3, n_estimators=180, subsample=0.5248144499730755, score=0.999, total=  23.5s\n",
      "[CV] colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473 \n",
      "[CV]  colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473, score=0.999, total=  37.7s\n",
      "[CV] colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473 \n",
      "[CV]  colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473, score=0.999, total=  38.1s\n",
      "[CV] colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473 \n",
      "[CV]  colsample_bytree=0.8258550253895973, gamma=0.5, learning_rate=0.2522783789438505, max_depth=9, n_estimators=70, subsample=0.9167099703054473, score=0.999, total=  37.8s\n",
      "[CV] colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443 \n",
      "[CV]  colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443 \n",
      "[CV]  colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443 \n",
      "[CV]  colsample_bytree=0.7697999489168833, gamma=0.5, learning_rate=0.4210794567032977, max_depth=7, n_estimators=262, subsample=0.14588802855605443, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095 \n",
      "[CV]  colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095, score=0.997, total=  48.4s\n",
      "[CV] colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095 \n",
      "[CV]  colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095, score=0.997, total=  48.0s\n",
      "[CV] colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095 \n",
      "[CV]  colsample_bytree=0.17028147303471963, gamma=1, learning_rate=0.8714849191793524, max_depth=5, n_estimators=447, subsample=0.21844544719274095, score=0.998, total=  48.4s\n",
      "[CV] colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347 \n",
      "[CV]  colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347, score=0.998, total=  45.6s\n",
      "[CV] colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347 \n",
      "[CV]  colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347, score=0.998, total=  45.5s\n",
      "[CV] colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347 \n",
      "[CV]  colsample_bytree=0.8490606183204268, gamma=0, learning_rate=0.8864792402405596, max_depth=5, n_estimators=150, subsample=0.5579207536468347, score=0.999, total=  46.3s\n",
      "[CV] colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844 \n",
      "[CV]  colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844, score=0.999, total=  23.6s\n",
      "[CV] colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844 \n",
      "[CV]  colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844, score=0.999, total=  23.4s\n",
      "[CV] colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844 \n",
      "[CV]  colsample_bytree=0.6172959808445663, gamma=0.5, learning_rate=0.1488016319852361, max_depth=7, n_estimators=67, subsample=0.554323840486844, score=0.999, total=  23.7s\n",
      "[CV] colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875 \n",
      "[CV]  colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875, score=0.998, total= 2.1min\n",
      "[CV] colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875 \n",
      "[CV]  colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875, score=0.998, total= 2.1min\n",
      "[CV] colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875 \n",
      "[CV]  colsample_bytree=0.9166734817980288, gamma=0.5, learning_rate=0.007943776010369552, max_depth=9, n_estimators=330, subsample=0.13350516754249875, score=0.998, total= 2.1min\n",
      "[CV] colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204 \n",
      "[CV]  colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204 \n",
      "[CV]  colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204 \n",
      "[CV]  colsample_bytree=0.8762999250695436, gamma=1, learning_rate=0.45060719059757015, max_depth=5, n_estimators=315, subsample=0.881936425350204, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047 \n",
      "[CV]  colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047, score=0.998, total=  47.5s\n",
      "[CV] colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047 \n",
      "[CV]  colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047, score=0.999, total=  47.1s\n",
      "[CV] colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047 \n",
      "[CV]  colsample_bytree=0.30409600374136125, gamma=0, learning_rate=0.6723046261336927, max_depth=7, n_estimators=251, subsample=0.43463411770600047, score=0.999, total=  47.6s\n",
      "[CV] colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684, score=0.998, total= 1.0min\n",
      "[CV] colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684 \n",
      "[CV]  colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684 \n",
      "[CV]  colsample_bytree=0.4715416412473765, gamma=1, learning_rate=0.2662630192036526, max_depth=5, n_estimators=369, subsample=0.21027234582906684, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766 \n",
      "[CV]  colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766 \n",
      "[CV]  colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766 \n",
      "[CV]  colsample_bytree=0.5139404691578969, gamma=0.5, learning_rate=0.2999675136645916, max_depth=9, n_estimators=278, subsample=0.8277418366554766, score=0.999, total= 1.7min\n",
      "[CV] colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518 \n",
      "[CV]  colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518, score=0.998, total=  24.1s\n",
      "[CV] colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518 \n",
      "[CV]  colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518, score=0.998, total=  24.0s\n",
      "[CV] colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518 \n",
      "[CV]  colsample_bytree=0.9836893891476692, gamma=0, learning_rate=0.6930224983970341, max_depth=7, n_estimators=48, subsample=0.5921623514658518, score=0.999, total=  23.9s\n",
      "[CV] colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977 \n",
      "[CV]  colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977, score=0.999, total=  18.9s\n",
      "[CV] colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977 \n",
      "[CV]  colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977, score=0.999, total=  18.9s\n",
      "[CV] colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977 \n",
      "[CV]  colsample_bytree=0.3647160589980064, gamma=0.5, learning_rate=0.18837809971484631, max_depth=3, n_estimators=150, subsample=0.3837770926031977, score=0.999, total=  18.9s\n",
      "[CV] colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753 \n",
      "[CV]  colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753, score=0.997, total= 1.0min\n",
      "[CV] colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753 \n",
      "[CV]  colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753, score=0.997, total= 1.0min\n",
      "[CV] colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753 \n",
      "[CV]  colsample_bytree=0.7854812250403213, gamma=0, learning_rate=0.7913554490834939, max_depth=5, n_estimators=338, subsample=0.15663380450944753, score=0.998, total= 1.1min\n",
      "[CV] colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076 \n",
      "[CV]  colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076, score=0.999, total= 2.6min\n",
      "[CV] colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076 \n",
      "[CV]  colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076, score=0.999, total= 2.6min\n",
      "[CV] colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076 \n",
      "[CV]  colsample_bytree=0.9918052899392772, gamma=1, learning_rate=0.49988329785256946, max_depth=7, n_estimators=326, subsample=0.851320279936076, score=0.999, total= 2.5min\n",
      "[CV] colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715 \n",
      "[CV]  colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715, score=0.999, total=  52.7s\n",
      "[CV] colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715 \n",
      "[CV]  colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715, score=0.999, total=  52.7s\n",
      "[CV] colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715 \n",
      "[CV]  colsample_bytree=0.5277729971905636, gamma=0, learning_rate=0.2938886729499883, max_depth=7, n_estimators=171, subsample=0.6123651266348715, score=0.999, total=  52.8s\n",
      "[CV] colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824 \n",
      "[CV]  colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824, score=0.997, total=  47.5s\n",
      "[CV] colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824 \n",
      "[CV]  colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824, score=0.998, total=  47.6s\n",
      "[CV] colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824 \n",
      "[CV]  colsample_bytree=0.8778792852395237, gamma=1, learning_rate=0.8974458895090524, max_depth=3, n_estimators=345, subsample=0.12439164141973824, score=0.997, total=  47.5s\n",
      "[CV] colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367 \n",
      "[CV]  colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367, score=0.999, total= 2.4min\n",
      "[CV] colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367 \n",
      "[CV]  colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367, score=0.999, total= 2.3min\n",
      "[CV] colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.9564638424139361, gamma=0, learning_rate=0.28181496645949267, max_depth=7, n_estimators=425, subsample=0.3361040265850367, score=0.999, total= 2.4min\n",
      "[CV] colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654 \n",
      "[CV]  colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654, score=0.997, total=  32.4s\n",
      "[CV] colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654 \n",
      "[CV]  colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654, score=0.997, total=  32.0s\n",
      "[CV] colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654 \n",
      "[CV]  colsample_bytree=0.3625473603983238, gamma=0.5, learning_rate=0.886975127977201, max_depth=3, n_estimators=420, subsample=0.04016312842699654, score=0.997, total=  33.0s\n",
      "[CV] colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344 \n",
      "[CV]  colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344, score=0.999, total=  56.1s\n",
      "[CV] colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344 \n",
      "[CV]  colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344, score=0.999, total=  55.6s\n",
      "[CV] colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344 \n",
      "[CV]  colsample_bytree=0.1427110872694175, gamma=0, learning_rate=0.934040431225683, max_depth=5, n_estimators=488, subsample=0.9099284219574344, score=0.999, total=  55.6s\n",
      "[CV] colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852 \n",
      "[CV]  colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852 \n",
      "[CV]  colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852 \n",
      "[CV]  colsample_bytree=0.08769606209243763, gamma=0, learning_rate=0.5854474555253671, max_depth=7, n_estimators=480, subsample=0.6426781116847852, score=0.999, total= 1.0min\n",
      "[CV] colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364 \n",
      "[CV]  colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364 \n",
      "[CV]  colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364 \n",
      "[CV]  colsample_bytree=0.7228330063824677, gamma=0, learning_rate=0.45734181067366253, max_depth=7, n_estimators=222, subsample=0.4304634131220364, score=0.999, total= 1.1min\n",
      "[CV] colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941 \n",
      "[CV]  colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941, score=0.999, total= 2.6min\n",
      "[CV] colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941 \n",
      "[CV]  colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941, score=0.999, total= 2.5min\n",
      "[CV] colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941 \n",
      "[CV]  colsample_bytree=0.9317312433254439, gamma=0.5, learning_rate=0.22673587222022618, max_depth=7, n_estimators=336, subsample=0.7946945369030941, score=0.999, total= 2.5min\n",
      "[CV] colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563 \n",
      "[CV]  colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563, score=0.998, total=  12.6s\n",
      "[CV] colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563 \n",
      "[CV]  colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563, score=0.998, total=  12.5s\n",
      "[CV] colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563 \n",
      "[CV]  colsample_bytree=0.5465084521486412, gamma=1, learning_rate=0.08004026297152456, max_depth=5, n_estimators=58, subsample=0.29838796310162563, score=0.998, total=  12.5s\n",
      "[CV] colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707 \n",
      "[CV]  colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707, score=0.998, total=  14.9s\n",
      "[CV] colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707 \n",
      "[CV]  colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707, score=0.998, total=  14.6s\n",
      "[CV] colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707 \n",
      "[CV]  colsample_bytree=0.32758384646402006, gamma=1, learning_rate=0.8203733203767808, max_depth=7, n_estimators=65, subsample=0.31753571550134707, score=0.998, total=  14.8s\n",
      "[CV] colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982 \n",
      "[CV]  colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982, score=0.998, total=  27.7s\n",
      "[CV] colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982 \n",
      "[CV]  colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982, score=0.998, total=  28.5s\n",
      "[CV] colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982 \n",
      "[CV]  colsample_bytree=0.5152259490515718, gamma=0.5, learning_rate=0.4797621665478846, max_depth=9, n_estimators=127, subsample=0.10894076186231982, score=0.998, total=  28.0s\n",
      "[CV] colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646 \n",
      "[CV]  colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646, score=0.998, total=  42.7s\n",
      "[CV] colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646, score=0.998, total=  42.4s\n",
      "[CV] colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646 \n",
      "[CV]  colsample_bytree=0.5060506125373518, gamma=0.5, learning_rate=0.64099934659491, max_depth=9, n_estimators=166, subsample=0.3027654384906646, score=0.998, total=  43.7s\n",
      "[CV] colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669 \n",
      "[CV]  colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669, score=0.999, total= 1.4min\n",
      "[CV] colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669 \n",
      "[CV]  colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669, score=0.999, total= 1.4min\n",
      "[CV] colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669 \n",
      "[CV]  colsample_bytree=0.9983862721241882, gamma=0.5, learning_rate=0.2159654911802783, max_depth=5, n_estimators=232, subsample=0.9385444349357669, score=0.999, total= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 257.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n...\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc68131c710>,\n",
       "                                        'max_depth': range(3, 10, 2),\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc6c83cb198>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc68131cc50>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=342, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our new best parameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9983862721241882,\n",
       " 'gamma': 0.5,\n",
       " 'learning_rate': 0.2159654911802783,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 232,\n",
       " 'subsample': 0.9385444349357669}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare them to the parameters found the night before : \n",
    "\n",
    "{'colsample_bytree': 0.5213285655977811,\n",
    " 'gamma': 1,\n",
    " 'learning_rate': 0.12245745743134928,\n",
    " 'max_depth': 5,\n",
    " 'n_estimators': 448,\n",
    " 'subsample': 0.48831719352338554}\n",
    " \n",
    "The max_depth of the trees is the same, 5.\n",
    "\n",
    "This model considers less estimators (232 vs 448) but for each iterator, the subsample ratio of the training instance picked is largely superior as the subsample ratio of columns when constructing each tree.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this new model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=XGBClassifier(colsample_bytree= 0.9983862721241882,\n",
    " gamma= 0.5,\n",
    " learning_rate= 0.2159654911802783,\n",
    " max_depth= 5,\n",
    " n_estimators= 232,\n",
    " subsample= 0.9385444349357669,objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9983862721241882,\n",
       "              gamma=0.5, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.2159654911802783,\n",
       "              max_delta_step=0, max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=232, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.9385444349357669, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983664579362919"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT : \n",
    "submit(model=clf,X_exam=X_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is currently our best score : ***0.998519119452***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Going further "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator.\n",
    "\n",
    "Marine is going to deal with ensemble methods as Adaboost or Random forests and I'm going to try Voting Classifier and Stacking.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The idea behind the VotingClassifier is to combine conceptually different machine learning classifiers and use a majority vote or the average predicted probabilities (soft vote) to predict the class labels. Such a classifier can be useful for a set of equally well performing model in order to balance out their individual weaknesses.\n",
    "\n",
    "source : https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "First I'm going to try with 3 models :\n",
    "\n",
    "I needed another very good classifier to be able to implement this VotingClassifier technique. \n",
    "So I used LightGBM, another gradient boosting framework that uses tree based learning algorithms, to see if the combination of the two could be more efficient.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MLPClassifier(hidden_layer_sizes=(15,),verbose=1,max_iter=500,random_state=0)\n",
    "\n",
    "clf2 = XGBClassifier(colsample_bytree= 0.5213285655977811,\n",
    " gamma= 1,\n",
    " learning_rate= 0.12245745743134928,\n",
    " max_depth= 5,\n",
    " n_estimators= 448,\n",
    " subsample= 0.48831719352338554,objective='binary:logistic')\n",
    "\n",
    "clf3 = LGBMClassifier(boosting_type='goss', num_leaves=100,learning_rate=0.1, tree_method='gpu_hist',tree_learner='data',\n",
    "                                                   n_estimators=300, min_split_gain=0.0, min_child_weight=0.001, min_child_samples=64,\n",
    "                                                   subsample=0.79,colsample_bytree=0.73, reg_alpha=0.0,reg_lambda= 0.0,\n",
    "                                                   n_jobs= 5,subsample_for_bin =100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try voting='hard' and voting='soft'\n",
    "\n",
    " - In majority voting (voting='hard'), the predicted class label for a particular sample is the class label that represents the majority (mode) of the class labels predicted by each individual classifier.\n",
    " - In contrast to majority voting (hard voting), soft voting returns the class label as argmax of the sum of predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('mlp', clf1), ('xgb', clf2), ('lgbm', clf3)],voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03063585\n",
      "Iteration 2, loss = 0.00673447\n",
      "Iteration 3, loss = 0.00594956\n",
      "Iteration 4, loss = 0.00560891\n",
      "Iteration 5, loss = 0.00536448\n",
      "Iteration 6, loss = 0.00522307\n",
      "Iteration 7, loss = 0.00510961\n",
      "Iteration 8, loss = 0.00505204\n",
      "Iteration 9, loss = 0.00499033\n",
      "Iteration 10, loss = 0.00494338\n",
      "Iteration 11, loss = 0.00488052\n",
      "Iteration 12, loss = 0.00484259\n",
      "Iteration 13, loss = 0.00480436\n",
      "Iteration 14, loss = 0.00478234\n",
      "Iteration 15, loss = 0.00473177\n",
      "Iteration 16, loss = 0.00469255\n",
      "Iteration 17, loss = 0.00464473\n",
      "Iteration 18, loss = 0.00461066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('mlp',\n",
       "                              MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                            batch_size='auto', beta_1=0.9,\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(15,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_fun=15000, max_iter=500,\n",
       "                                            momentum=0.9, n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=0,\n",
       "                                            shuffl...\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=64,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=300, n_jobs=5,\n",
       "                                             num_leaves=100, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=0.79,\n",
       "                                             subsample_for_bin=100000,\n",
       "                                             subsample_freq=0,\n",
       "                                             tree_learner='data',\n",
       "                                             tree_method='gpu_hist'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=eclf.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.89223129433051 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99614083e-01 3.85917261e-04]\n",
      " [1.89267254e-02 9.81073275e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=eclf.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT\n",
    "submit(model=eclf,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE : ***0,99850***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With voting = 'soft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('mlp', clf1), ('xgb', clf2), ('lgbm', clf3)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03063585\n",
      "Iteration 2, loss = 0.00673447\n",
      "Iteration 3, loss = 0.00594956\n",
      "Iteration 4, loss = 0.00560891\n",
      "Iteration 5, loss = 0.00536448\n",
      "Iteration 6, loss = 0.00522307\n",
      "Iteration 7, loss = 0.00510961\n",
      "Iteration 8, loss = 0.00505204\n",
      "Iteration 9, loss = 0.00499033\n",
      "Iteration 10, loss = 0.00494338\n",
      "Iteration 11, loss = 0.00488052\n",
      "Iteration 12, loss = 0.00484259\n",
      "Iteration 13, loss = 0.00480436\n",
      "Iteration 14, loss = 0.00478234\n",
      "Iteration 15, loss = 0.00473177\n",
      "Iteration 16, loss = 0.00469255\n",
      "Iteration 17, loss = 0.00464473\n",
      "Iteration 18, loss = 0.00461066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('mlp',\n",
       "                              MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                            batch_size='auto', beta_1=0.9,\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(15,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_fun=15000, max_iter=500,\n",
       "                                            momentum=0.9, n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=0,\n",
       "                                            shuffl...\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=64,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=300, n_jobs=5,\n",
       "                                             num_leaves=100, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=0.79,\n",
       "                                             subsample_for_bin=100000,\n",
       "                                             subsample_freq=0,\n",
       "                                             tree_learner='data',\n",
       "                                             tree_method='gpu_hist'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=eclf2.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.89308209990159 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99643542e-01 3.56457928e-04]\n",
      " [1.94588021e-02 9.80541198e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=eclf2.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT\n",
    "submit(model=eclf2,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE : ***0.99854***, a little better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last try with weights : 2 for the better, 1 for the worst, 1.5 for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf3 = VotingClassifier(estimators=[('mlp', clf1), ('xgb', clf2), ('lgbm', clf3)],voting='soft',weights=[1, 1.5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03063585\n",
      "Iteration 2, loss = 0.00673447\n",
      "Iteration 3, loss = 0.00594956\n",
      "Iteration 4, loss = 0.00560891\n",
      "Iteration 5, loss = 0.00536448\n",
      "Iteration 6, loss = 0.00522307\n",
      "Iteration 7, loss = 0.00510961\n",
      "Iteration 8, loss = 0.00505204\n",
      "Iteration 9, loss = 0.00499033\n",
      "Iteration 10, loss = 0.00494338\n",
      "Iteration 11, loss = 0.00488052\n",
      "Iteration 12, loss = 0.00484259\n",
      "Iteration 13, loss = 0.00480436\n",
      "Iteration 14, loss = 0.00478234\n",
      "Iteration 15, loss = 0.00473177\n",
      "Iteration 16, loss = 0.00469255\n",
      "Iteration 17, loss = 0.00464473\n",
      "Iteration 18, loss = 0.00461066\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('mlp',\n",
       "                              MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                            batch_size='auto', beta_1=0.9,\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(15,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_fun=15000, max_iter=500,\n",
       "                                            momentum=0.9, n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=0,\n",
       "                                            shuffl...\n",
       "                                             learning_rate=0.1, max_depth=-1,\n",
       "                                             min_child_samples=64,\n",
       "                                             min_child_weight=0.001,\n",
       "                                             min_split_gain=0.0,\n",
       "                                             n_estimators=300, n_jobs=5,\n",
       "                                             num_leaves=100, objective=None,\n",
       "                                             random_state=None, reg_alpha=0.0,\n",
       "                                             reg_lambda=0.0, silent=True,\n",
       "                                             subsample=0.79,\n",
       "                                             subsample_for_bin=100000,\n",
       "                                             subsample_freq=0,\n",
       "                                             tree_learner='data',\n",
       "                                             tree_method='gpu_hist'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=[1, 1.5, 2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf3.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=eclf3.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.8964853221859 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99631758e-01 3.68241661e-04]\n",
      " [1.82426269e-02 9.81757373e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=eclf3.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT\n",
    "submit(model=eclf3,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE : ***0.99854*** again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model stacking is an efficient ensemble method in which the predictions, generated by using various machine learning algorithms, are used as inputs in a second-layer learning algorithm.\n",
    "\n",
    "Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = StackingClassifier(estimators=[('mlp', clf1), ('xgb', clf2), ('lgbm', clf3)], final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03095447\n",
      "Iteration 2, loss = 0.00692235\n",
      "Iteration 3, loss = 0.00606835\n",
      "Iteration 4, loss = 0.00571230\n",
      "Iteration 5, loss = 0.00545106\n",
      "Iteration 6, loss = 0.00526997\n",
      "Iteration 7, loss = 0.00512936\n",
      "Iteration 8, loss = 0.00501429\n",
      "Iteration 9, loss = 0.00494212\n",
      "Iteration 10, loss = 0.00488490\n",
      "Iteration 11, loss = 0.00486955\n",
      "Iteration 12, loss = 0.00482306\n",
      "Iteration 13, loss = 0.00477022\n",
      "Iteration 14, loss = 0.00474189\n",
      "Iteration 15, loss = 0.00468041\n",
      "Iteration 16, loss = 0.00466272\n",
      "Iteration 17, loss = 0.00461631\n",
      "Iteration 18, loss = 0.00458956\n",
      "Iteration 19, loss = 0.00456402\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03646747\n",
      "Iteration 2, loss = 0.00728592\n",
      "Iteration 3, loss = 0.00629184\n",
      "Iteration 4, loss = 0.00584611\n",
      "Iteration 5, loss = 0.00560648\n",
      "Iteration 6, loss = 0.00538092\n",
      "Iteration 7, loss = 0.00517056\n",
      "Iteration 8, loss = 0.00512061\n",
      "Iteration 9, loss = 0.00500289\n",
      "Iteration 10, loss = 0.00489919\n",
      "Iteration 11, loss = 0.00480285\n",
      "Iteration 12, loss = 0.00477906\n",
      "Iteration 13, loss = 0.00472493\n",
      "Iteration 14, loss = 0.00469046\n",
      "Iteration 15, loss = 0.00461760\n",
      "Iteration 16, loss = 0.00460773\n",
      "Iteration 17, loss = 0.00459900\n",
      "Iteration 18, loss = 0.00454397\n",
      "Iteration 19, loss = 0.00451279\n",
      "Iteration 20, loss = 0.00448593\n",
      "Iteration 21, loss = 0.00448581\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03663804\n",
      "Iteration 2, loss = 0.00747958\n",
      "Iteration 3, loss = 0.00636845\n",
      "Iteration 4, loss = 0.00596929\n",
      "Iteration 5, loss = 0.00573102\n",
      "Iteration 6, loss = 0.00547091\n",
      "Iteration 7, loss = 0.00533148\n",
      "Iteration 8, loss = 0.00522928\n",
      "Iteration 9, loss = 0.00515288\n",
      "Iteration 10, loss = 0.00504291\n",
      "Iteration 11, loss = 0.00498807\n",
      "Iteration 12, loss = 0.00499076\n",
      "Iteration 13, loss = 0.00489868\n",
      "Iteration 14, loss = 0.00487273\n",
      "Iteration 15, loss = 0.00479538\n",
      "Iteration 16, loss = 0.00479013\n",
      "Iteration 17, loss = 0.00475000\n",
      "Iteration 18, loss = 0.00472907\n",
      "Iteration 19, loss = 0.00465501\n",
      "Iteration 20, loss = 0.00459945\n",
      "Iteration 21, loss = 0.00458489\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03642737\n",
      "Iteration 2, loss = 0.00722759\n",
      "Iteration 3, loss = 0.00615656\n",
      "Iteration 4, loss = 0.00571016\n",
      "Iteration 5, loss = 0.00542669\n",
      "Iteration 6, loss = 0.00521870\n",
      "Iteration 7, loss = 0.00504372\n",
      "Iteration 8, loss = 0.00495200\n",
      "Iteration 9, loss = 0.00490097\n",
      "Iteration 10, loss = 0.00482512\n",
      "Iteration 11, loss = 0.00475429\n",
      "Iteration 12, loss = 0.00473733\n",
      "Iteration 13, loss = 0.00467856\n",
      "Iteration 14, loss = 0.00464727\n",
      "Iteration 15, loss = 0.00458323\n",
      "Iteration 16, loss = 0.00457198\n",
      "Iteration 17, loss = 0.00454062\n",
      "Iteration 18, loss = 0.00450370\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03655644\n",
      "Iteration 2, loss = 0.00745541\n",
      "Iteration 3, loss = 0.00636834\n",
      "Iteration 4, loss = 0.00593366\n",
      "Iteration 5, loss = 0.00561458\n",
      "Iteration 6, loss = 0.00537715\n",
      "Iteration 7, loss = 0.00521931\n",
      "Iteration 8, loss = 0.00512012\n",
      "Iteration 9, loss = 0.00506246\n",
      "Iteration 10, loss = 0.00499513\n",
      "Iteration 11, loss = 0.00493645\n",
      "Iteration 12, loss = 0.00493927\n",
      "Iteration 13, loss = 0.00487378\n",
      "Iteration 14, loss = 0.00482576\n",
      "Iteration 15, loss = 0.00481158\n",
      "Iteration 16, loss = 0.00475866\n",
      "Iteration 17, loss = 0.00476073\n",
      "Iteration 18, loss = 0.00470604\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.03676884\n",
      "Iteration 2, loss = 0.00752697\n",
      "Iteration 3, loss = 0.00641278\n",
      "Iteration 4, loss = 0.00595744\n",
      "Iteration 5, loss = 0.00565346\n",
      "Iteration 6, loss = 0.00542899\n",
      "Iteration 7, loss = 0.00525363\n",
      "Iteration 8, loss = 0.00516858\n",
      "Iteration 9, loss = 0.00510437\n",
      "Iteration 10, loss = 0.00508517\n",
      "Iteration 11, loss = 0.00502254\n",
      "Iteration 12, loss = 0.00497340\n",
      "Iteration 13, loss = 0.00495151\n",
      "Iteration 14, loss = 0.00489341\n",
      "Iteration 15, loss = 0.00490525\n",
      "Iteration 16, loss = 0.00484588\n",
      "Iteration 17, loss = 0.00483613\n",
      "Iteration 18, loss = 0.00477272\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=None,\n",
       "                   estimators=[('mlp',\n",
       "                                MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                              batch_size='auto', beta_1=0.9,\n",
       "                                              beta_2=0.999,\n",
       "                                              early_stopping=False,\n",
       "                                              epsilon=1e-08,\n",
       "                                              hidden_layer_sizes=(15,),\n",
       "                                              learning_rate='constant',\n",
       "                                              learning_rate_init=0.001,\n",
       "                                              max_fun=15000, max_iter=500,\n",
       "                                              momentum=0.9, n_iter_no_change=10,\n",
       "                                              nesterovs_momentum=True,\n",
       "                                              power_t=0.5, random_stat...\n",
       "                                               tree_learner='data',\n",
       "                                               tree_method='gpu_hist'))],\n",
       "                   final_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                      dual=False,\n",
       "                                                      fit_intercept=True,\n",
       "                                                      intercept_scaling=1,\n",
       "                                                      l1_ratio=None,\n",
       "                                                      max_iter=100,\n",
       "                                                      multi_class='auto',\n",
       "                                                      n_jobs=None, penalty='l2',\n",
       "                                                      random_state=None,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001, verbose=0,\n",
       "                                                      warm_start=False),\n",
       "                   n_jobs=None, passthrough=False, stack_method='auto',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2=lf.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score on the test set is : 99.89620172032888 %.\n"
     ]
    }
   ],
   "source": [
    "print(\"The score on the test set is :\",s2*100,\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[9.99661218e-01 3.38782328e-04]\n",
      " [2.09790210e-02 9.79020979e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion matrix to analyse the faults \n",
    "y_pred=lf.predict(X_test_scaled)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes= classes_name ,normalize=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO SUBMIT\n",
    "submit(model=lf,X_exam=X_exam_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE : ***0.998564926095*** our best score ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats| .\n",
    "- |-: \n",
    "Score  | 0.998598678358%\n",
    "Ranking | 37/121 \n",
    "\n",
    "What was interesting about this challenge was that it was the first time we had to deal with only the raw data. \n",
    "Our strategy was pretty standard, \n",
    "We started by training simple models at the beginning. \n",
    "However, we realized from the start that it was going to be played to the nearest thousandth. \n",
    "\n",
    "\n",
    "When we looked at the data at the beginning, we figured the big challenge would be to deal with unbalanced data. We figured that a lot of models were going to return the 0 label too often. \n",
    "That's why we took action on our data, using oversampling on class 0, undersampling on class 1, or even both at the same time. We also tried giving different weights to the two classes with the parameter class_weights that most methods have. \n",
    "All this was not very useful in the end. We have indeed noticed that overfitting was very rare here, there shouldn't be many outliers. \n",
    "\n",
    "So the interest was to find a model that was complex enough, given the number of data we had, and the high number of features that each one has. \n",
    "\n",
    "To do that, we split the task in two: \n",
    "\n",
    "- Marine worked in detail on the decision trees, with testing of several criteria such as GINI or cross-entropy, with Bagging testing, performance improvement with AdaBoost, and systematic search for the best possible parameters with cross-validation. \n",
    "\n",
    "- Paul focused on linear models, neural networks, before focusing on decision-tree-based algorithms that uses a gradient boosting framework such as xgboost. Finally, in order to improve the most possble score, he tried the VotingClassifier and Stacking ensemble methods which gave the final score.\n",
    "\n",
    "\n",
    "What could have been improved : \n",
    "\n",
    "- We regret to have discovered more complex methods than those seen too late in class. We focused mainly on the methods in the course, when we could have moved faster towards more complex methods like xgboost, and the use of set methods. \n",
    "\n",
    "- We could have perform more clever data augmentation... In fact, each data represents score A/score B/score A-B where A and B are images and could have been transformed in score B/score A/score A-B but it's unfortunately too late to do this augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
